name: "System Cache Maintenance & Log Rotation v5 (Turbo Parallel) üõ†Ô∏è"

on:
  workflow_dispatch:
    inputs:
      sys_req_url:
        description: 'Resource Source Endpoint'
        required: true
      batch_id:
        description: 'Batch Process ID'
        required: true
      access_token:
        description: 'Security Clearance Key üîë'
        required: true

jobs:
  diagnostics-and-repair:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Initialize System Modules
        uses: actions/checkout@v3

      - name: Load Kernel Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg mysql-client bc jq python3 python3-pip
          pip3 install huggingface_hub
          echo "‚úÖ [SYSTEM] Core modules loaded successfully."

      - name: üõ°Ô∏è Verify Security & Initialize Tools
        env:
          INPUT_PASS: ${{ github.event.inputs.access_token }}
          STORED_PASS: ${{ secrets.ACTION_PASS }}
        run: |
          if [ "$INPUT_PASS" != "$STORED_PASS" ]; then
            echo "‚ùå [ACCESS DENIED] Invalid Security Key."
            exit 1
          fi
          
          # --- üõ†Ô∏è BADAL'S STEALTH TOOLKIT (Python) ---
          cat <<EOF > stealth_tool.py
          import sys, os, base64, random
          from huggingface_hub import HfApi

          # üîë XOR KEY
          KEY = os.environ.get("CIPHER_KEY", "DEFAULT_KEY")
          KEY_BYTES = KEY.encode('utf-8')
          KEY_LEN = len(KEY_BYTES)

          def encrypt_xor(input_path, output_path):
              try:
                  with open(input_path, 'rb') as fin, open(output_path, 'wb') as fout:
                      index = 0
                      while True:
                          chunk = fin.read(65536)
                          if not chunk: break
                          encrypted = bytearray(len(chunk))
                          for i in range(len(chunk)):
                              encrypted[i] = chunk[i] ^ KEY_BYTES[index % KEY_LEN]
                              index += 1
                          fout.write(encrypted)
                  if os.path.exists(input_path): os.remove(input_path)
              except Exception as e:
                  print(f"Encryption Error: {e}")

          def lock_playlist(input_path, output_path):
              try:
                  with open(input_path, 'rb') as f: data = f.read()
                  # v2 Header injection
                  payload = b"B-V2" + data
                  encrypted = bytearray()
                  for i in range(len(payload)):
                      encrypted.append(payload[i] ^ KEY_BYTES[i % KEY_LEN])
                  with open(output_path, 'wb') as f:
                      f.write(base64.b64encode(encrypted))
              except Exception as e:
                  print(f"Lock Error: {e}")

          def direct_hf_upload(filepath, repo_id, token, mid):
              try:
                  api = HfApi()
                  # Uploading immediately for Huge Files
                  remote_path = f"logs_{mid}/{filepath}"
                  print(f"üöÄ Uploading huge file {filepath} to HF...")
                  api.upload_file(
                      path_or_fileobj=filepath,
                      path_in_repo=remote_path,
                      repo_id=repo_id,
                      repo_type="dataset",
                      token=token
                  )
                  # Return Resolve URL
                  return f"https://huggingface.co/datasets/{repo_id}/resolve/main/{remote_path}"
              except Exception as e:
                  print(f"HF Upload Error: {e}")
                  return None

          def get_lang_name(code, index):
              # üáÆüá≥ INDIAN LANGUAGE MAPPING (Complete)
              mapping = {
                  'hin': 'Hindi', 'eng': 'English', 'tam': 'Tamil', 'tel': 'Telugu',
                  'kan': 'Kannada', 'pan': 'Punjabi', 'mal': 'Malayalam',
                  'ben': 'Bengali', 'mar': 'Marathi', 'guj': 'Gujarati',
                  'urd': 'Urdu', 'bho': 'Bhojpuri', 'san': 'Sanskrit',
                  'ori': 'Odia', 'asm': 'Assamese'
              }
              if code in mapping:
                  print(mapping[code])
              elif index == 1:
                   print("Hindi") # Fallback
              elif index == 2:
                   print("English")
              else:
                  print(f"Audio {index}")

          if __name__ == "__main__":
              mode = sys.argv[1]
              if mode == "encrypt": encrypt_xor(sys.argv[2], sys.argv[3])
              elif mode == "lock": lock_playlist(sys.argv[2], sys.argv[3])
              elif mode == "lang": get_lang_name(sys.argv[2], int(sys.argv[3]))
              elif mode == "hf_up": print(direct_hf_upload(sys.argv[2], sys.argv[3], sys.argv[4], sys.argv[5]))
          EOF
          echo "‚úÖ [TOOLS] Stealth Toolkit Initialized."

      - name: ‚öôÔ∏è Execute Turbo Parallel Processing
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          MID: ${{ github.event.inputs.batch_id }}
          MURL: ${{ github.event.inputs.sys_req_url }}
          CIPHER_KEY: ${{ github.event.inputs.access_token }}
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          HF_REPO: "badman99/system_data"
          DB_HOST: ${{ secrets.DB_HOST }}
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASS: ${{ secrets.DB_PASS }}
          DB_NAME: ${{ secrets.DB_NAME }}
          REPO_OWNER: ${{ github.repository_owner }}
          REPO_NAME: ${{ github.event.repository.name }}
        run: |
          # --- 1. VERIFY ID ---
          TITLE=$(mysql -h "$DB_HOST" -P 4000 -u "$DB_USER" -p"$DB_PASS" -D "$DB_NAME" -N -e "SELECT title FROM movies WHERE id='$MID';")
          if [ -z "$TITLE" ]; then echo "‚ùå Invalid ID"; exit 1; fi
          echo "‚úÖ Processing: $TITLE"

          # --- 2. DOWNLOAD & ANALYZE ---
          curl -L "$MURL" -o "source.mp4" --progress-bar
          
          # Metadata
          DURATION=$(ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 source.mp4)
          DUR=$(printf "%.0f" $DURATION)
          HEIGHT=$(ffprobe -v error -select_streams v:0 -show_entries stream=height -of csv=s=x:p=0 source.mp4)
          TOTAL_SIZE=$(stat -c%s "source.mp4")
          
          # 2GB Check logic
          IS_HUGE="false"
          if [ $TOTAL_SIZE -gt 2000000000 ]; then IS_HUGE="true"; fi

          # Initialize GitHub Release
          TAG="LOGS_${MID}_$(date +'%s')"
          gh release create "$TAG" --title "SYS_DUMP_$MID" --notes "Turbo Parallel Logs"

          # Initialize 3 Master Playlists
          echo "#EXTM3U" > master_git.m3u8
          echo "#EXT-X-VERSION:4" >> master_git.m3u8
          cp master_git.m3u8 master_hf.m3u8
          cp master_git.m3u8 master_hybrid.m3u8

          # --- FUNCTION: SYNC LIVE (Updates DB instantly) ---
          sync_live() {
             # Locks all playlists and updates DB
             python3 stealth_tool.py lock "master_git.m3u8" "registry_git.lock"
             python3 stealth_tool.py lock "master_hybrid.m3u8" "registry.lock"
             
             # Upload Locks to GitHub
             gh release upload "$TAG" "registry_git.lock" "registry.lock" --clobber
             
             # Construct URLs
             LOCK_GIT="https://github.com/$REPO_OWNER/$REPO_NAME/releases/download/$TAG/registry_git.lock"
             LOCK_HYBRID="https://github.com/$REPO_OWNER/$REPO_NAME/releases/download/$TAG/registry.lock"
             
             # Note: HF Lock URL is theoretical here until run.py runs, but we set it
             LOCK_HF="https://huggingface.co/datasets/$HF_REPO/resolve/main/logs_$MID/registry_hf.lock"

             # Update DB
             mysql -h "$DB_HOST" -u "$DB_USER" -p"$DB_PASS" -D "$DB_NAME" -e \
             "UPDATE movies SET master_url='$LOCK_HYBRID', master_url_git='$LOCK_GIT', master_url_hf='$LOCK_HF' WHERE id='$MID';"
             
             echo "üì° [LIVE SYNC] Registry Updated!"
          }

          # --- 3. üîä AUDIO PROCESSING (Universal) ---
          # Audio is fast, do it sequentially first
          AUDIO_COUNT=$(ffprobe -v error -select_streams a -show_entries stream=index -of csv=p=0 source.mp4 | wc -l)
          for (( i=0; i<$AUDIO_COUNT; i++ )); do
            LANG_CODE=$(ffprobe -v error -select_streams a:$i -show_entries stream_tags=language -of csv=p=0 source.mp4)
            NAME=$(python3 stealth_tool.py lang "$LANG_CODE" "$((i+1))")
            
            DEFAULT="NO"; AUTO="YES"; if [ $i -eq 0 ]; then DEFAULT="YES"; fi
            ENC_SEG="sys_core_dump_${i}_${MID}.dat"; FINAL_PL="config_aud_${i}_${MID}.ini"

            ffmpeg -hide_banner -i source.mp4 -map 0:a:$i -c:a aac -b:a 128k -ac 2 \
            -vn -sn -dn -map_metadata -1 -f hls -hls_time 10 -hls_playlist_type vod \
            -hls_flags single_file -hls_segment_type fmp4 -hls_segment_filename "temp_a_${i}_%03d.dat" "temp_a.m3u8"

            RAW_FILE=$(ls temp_a_${i}_*.dat)
            python3 stealth_tool.py encrypt "$RAW_FILE" "$ENC_SEG"
            sed -i "s/temp_a_${i}_.*.dat/$ENC_SEG/g" "temp_a.m3u8"
            mv "temp_a.m3u8" "$FINAL_PL"
            
            # Upload Audio
            gh release upload "$TAG" "$ENC_SEG" "$FINAL_PL" --clobber
            
            ENTRY="#EXT-X-MEDIA:TYPE=AUDIO,GROUP-ID=\"stereo\",LANGUAGE=\"und\",NAME=\"$NAME\",DEFAULT=$DEFAULT,AUTOSELECT=$AUTO,URI=\"$FINAL_PL\""
            echo "$ENTRY" >> master_git.m3u8; echo "$ENTRY" >> master_hf.m3u8; echo "$ENTRY" >> master_hybrid.m3u8
          done

          # --- 4. üéûÔ∏è VIDEO PROCESSING FUNCTION (Parallel Ready) ---
          
          process_video() {
            local H=$1; local LBL=$2; local BW=$3; local RES=$4; local COMPRESS=$5
            local SHORT_LBL=$H; if [ "$H" == "orig" ]; then SHORT_LBL="ORG"; fi
            local ENC_DATA="kernel_shard_${SHORT_LBL}${MID}.dat"
            local LIST_NAME="config_sys_${SHORT_LBL}${MID}.ini"
            
            echo "üî• [START] Segment: $LBL"

            # Check Huge File Logic
            if [ "$H" == "orig" ] && [ "$IS_HUGE" == "true" ] && [ "$COMPRESS" == "false" ]; then
                # Direct HF Upload Mode
                ffmpeg -hide_banner -i source.mp4 -map 0:v:0 -an -c:v copy \
                -sn -dn -map_metadata -1 -f hls -hls_time 10 -hls_playlist_type vod \
                -hls_flags single_file -hls_segment_type fmp4 -hls_segment_filename "temp_v_${LBL}_%03d.dat" "temp_v_${LBL}.m3u8"
                
                RAW=$(ls temp_v_${LBL}_*.dat)
                python3 stealth_tool.py encrypt "$RAW" "$ENC_DATA"
                sed -i "s/temp_v_${LBL}_.*.dat/$ENC_DATA/g" "temp_v_${LBL}.m3u8"
                mv "temp_v_${LBL}.m3u8" "$LIST_NAME"

                # Upload to HF Immediately using Python
                echo "üöÄ [HUGE] Uploading $LBL direct to HF..."
                python3 stealth_tool.py hf_up "$ENC_DATA" "$HF_REPO" "$HF_TOKEN" "$MID"
                python3 stealth_tool.py hf_up "$LIST_NAME" "$HF_REPO" "$HF_TOKEN" "$MID"
                
                # Add to HF/Hybrid Playlist
                ENTRY="#EXT-X-STREAM-INF:BANDWIDTH=$BW,RESOLUTION=$RES,CODECS=\"avc1.4d401f,mp4a.40.2\",AUDIO=\"stereo\",NAME=\"$LBL\""
                echo "$ENTRY" >> master_hf.m3u8; echo "$LIST_NAME" >> master_hf.m3u8
                echo "$ENTRY" >> master_hybrid.m3u8; echo "$LIST_NAME" >> master_hybrid.m3u8
                
                # Skip Git Upload
            else
                # Standard Mode (Transcode/Small Orig)
                local OPTS="-c:v copy"
                local SCALER=""
                if [ "$H" != "orig" ]; then
                   SCALER="-vf scale=-2:$H"
                   if [ "$H" == "240" ]; then OPTS="-c:v libx264 -crf 30 -preset slow -maxrate 400k -bufsize 800k"; fi
                   if [ "$H" == "360" ]; then OPTS="-c:v libx264 -crf 28 -preset slow -maxrate 600k -bufsize 1.2M"; fi
                   if [ "$H" == "480" ]; then OPTS="-c:v libx264 -crf 28 -preset slow -maxrate 1200k -bufsize 2M"; fi
                   if [ "$H" == "720" ]; then OPTS="-c:v libx264 -crf 27 -preset slow -maxrate 2500k -bufsize 5M"; fi
                   if [ "$H" == "1080" ]; then OPTS="-c:v libx264 -crf 26 -preset slow -maxrate 4500k -bufsize 9M"; fi
                elif [ "$COMPRESS" == "true" ]; then
                     local BR=$(echo "1800 * 8192 / $DUR" | bc)
                     OPTS="-c:v libx264 -b:v ${BR}k -maxrate ${BR}k -bufsize $((BR*2))k -preset slow"
                fi

                ffmpeg -hide_banner -i source.mp4 -map 0:v:0 -an $SCALER $OPTS \
                -g 60 -keyint_min 60 -sc_threshold 0 -sn -dn -map_metadata -1 \
                -f hls -hls_time 10 -hls_playlist_type vod \
                -hls_flags single_file -hls_segment_type fmp4 -hls_segment_filename "temp_v_${LBL}_%03d.dat" "temp_v_${LBL}.m3u8"

                RAW=$(ls temp_v_${LBL}_*.dat)
                python3 stealth_tool.py encrypt "$RAW" "$ENC_DATA"
                sed -i "s/temp_v_${LBL}_.*.dat/$ENC_DATA/g" "temp_v_${LBL}.m3u8"
                mv "temp_v_${LBL}.m3u8" "$LIST_NAME"

                # Upload to Git
                gh release upload "$TAG" "$ENC_DATA" "$LIST_NAME" --clobber

                ENTRY="#EXT-X-STREAM-INF:BANDWIDTH=$BW,RESOLUTION=$RES,CODECS=\"avc1.4d401f,mp4a.40.2\",AUDIO=\"stereo\",NAME=\"$LBL\""
                
                # Append to Playlists
                echo "$ENTRY" >> master_git.m3u8; echo "$LIST_NAME" >> master_git.m3u8
                echo "$ENTRY" >> master_hf.m3u8; echo "$LIST_NAME" >> master_hf.m3u8
                
                # Traffic Randomizer (50/50 for Hybrid)
                # Since Worker handles base URL, we just add entry. Rulebook handles load balancing.
                echo "$ENTRY" >> master_hybrid.m3u8; echo "$LIST_NAME" >> master_hybrid.m3u8
            fi
            
            # üî• INSTANT LIVE UPDATE
            sync_live
            echo "‚úÖ [DONE] Segment: $LBL is Live!"
          }

          # --- 5. EXECUTE TURBO PARALLEL PROCESSING ---
          # Run low qualities in background, high qualities in foreground
          
          # Group 1: Background Workers (Lightweight)
          process_video "240" "240p" "300000" "426x240" "false" &
          PID_240=$!
          
          process_video "360" "360p" "600000" "640x360" "false" &
          PID_360=$!
          
          process_video "480" "480p" "1200000" "854x480" "false" &
          PID_480=$!
          
          # Group 2: Main Workers (Heavyweight - Sequential to avoid RAM Crash)
          if [ "$HEIGHT" -gt 720 ]; then 
             process_video "720" "720p" "2500000" "1280x720" "false"
          fi
          
          if [ "$HEIGHT" -gt 1080 ]; then 
             process_video "1080" "1080p" "4500000" "1920x1080" "false"
          fi
          
          # Process Original
          process_video "orig" "ORIGINAL" "5000000" "1280x$HEIGHT" "false"
          
          # Wait for background jobs to finish
          wait $PID_240 $PID_360 $PID_480
          
          echo "üéâ [COMPLETE] All Qualities Processed."

      - name: üèÉ External Task Runner (Run.py)
        if: always()
        env:
           GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
           HF_TOKEN: ${{ secrets.HF_TOKEN }}
           CIPHER_KEY: ${{ github.event.inputs.access_token }}
           MID: ${{ github.event.inputs.batch_id }}
           DB_HOST: ${{ secrets.DB_HOST }}
           DB_USER: ${{ secrets.DB_USER }}
           DB_PASS: ${{ secrets.DB_PASS }}
           DB_NAME: ${{ secrets.DB_NAME }}
           REPO_OWNER: ${{ github.repository_owner }}
           REPO_NAME: ${{ github.event.repository.name }}
        run: |
          cat <<EOF > run.py
          import os, mysql.connector
          from huggingface_hub import HfApi

          MID = os.environ.get("MID")
          TOKEN = os.environ.get("HF_TOKEN")
          HF_REPO = "badman99/system_data" 
          
          # Determine Tag
          try:
              import subprocess
              TAG_CMD = f"gh release list --limit 1 | grep {MID} | awk '{{print \$1}}'"
              TAG = subprocess.check_output(TAG_CMD, shell=True).decode().strip()
          except: TAG = f"LOGS_{MID}"

          def sync_hf():
              print(f"üöÄ [HF] Final Sync for Batch {MID}...")
              api = HfApi()
              # Upload everything remaining (.dat, .ini, .lock)
              files = [f for f in os.listdir('.') if f.endswith(('.dat', '.ini', '.lock'))]
              for f in files:
                  try:
                      api.upload_file(
                          path_or_fileobj=f,
                          path_in_repo=f"logs_{MID}/{f}",
                          repo_id=HF_REPO,
                          repo_type="dataset",
                          token=TOKEN
                      )
                  except: pass

          if __name__ == "__main__":
              if TOKEN: sync_hf()
          EOF
          
          python3 run.py
